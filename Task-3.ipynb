{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3e179f",
   "metadata": {},
   "outputs": [],
   "source": [
    " from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406e11fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipeline in module transformers.pipelines:\n",
      "\n",
      "pipeline(task: str = None, model: Optional = None, config: Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None, tokenizer: Union[str, transformers.tokenization_utils.PreTrainedTokenizer, transformers.tokenization_utils_fast.PreTrainedTokenizerFast, NoneType] = None, feature_extractor: Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, use_auth_token: Union[str, bool, NoneType] = None, device: Union[int, str, ForwardRef('torch.device'), NoneType] = None, device_map=None, torch_dtype=None, trust_remote_code: Optional[bool] = None, model_kwargs: Dict[str, Any] = None, pipeline_class: Optional[Any] = None, **kwargs) -> transformers.pipelines.base.Pipeline\n",
      "    Utility factory method to build a [`Pipeline`].\n",
      "    \n",
      "    Pipelines are made of:\n",
      "    \n",
      "        - A [tokenizer](tokenizer) in charge of mapping raw textual input to token.\n",
      "        - A [model](model) to make predictions from the inputs.\n",
      "        - Some (optional) post processing for enhancing model's output.\n",
      "    \n",
      "    Args:\n",
      "        task (`str`):\n",
      "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
      "    \n",
      "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
      "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
      "            - `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
      "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
      "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
      "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
      "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
      "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
      "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
      "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
      "              [`TextClassificationPipeline`].\n",
      "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
      "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
      "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
      "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
      "    \n",
      "        model (`str` or [`PreTrainedModel`] or [`TFPreTrainedModel`], *optional*):\n",
      "            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n",
      "            actual instance of a pretrained model inheriting from [`PreTrainedModel`] (for PyTorch) or\n",
      "            [`TFPreTrainedModel`] (for TensorFlow).\n",
      "    \n",
      "            If not provided, the default for the `task` will be loaded.\n",
      "        config (`str` or [`PretrainedConfig`], *optional*):\n",
      "            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n",
      "            identifier or an actual pretrained model configuration inheriting from [`PretrainedConfig`].\n",
      "    \n",
      "            If not provided, the default configuration file for the requested model will be used. That means that if\n",
      "            `model` is given, its default configuration will be used. However, if `model` is not supplied, this\n",
      "            `task`'s default model's config is used instead.\n",
      "        tokenizer (`str` or [`PreTrainedTokenizer`], *optional*):\n",
      "            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained tokenizer inheriting from [`PreTrainedTokenizer`].\n",
      "    \n",
      "            If not provided, the default tokenizer for the given `model` will be loaded (if it is a string). If `model`\n",
      "            is not specified or not a string, then the default tokenizer for `config` is loaded (if it is a string).\n",
      "            However, if `config` is also not given or not a string, then the default tokenizer for the given `task`\n",
      "            will be loaded.\n",
      "        feature_extractor (`str` or [`PreTrainedFeatureExtractor`], *optional*):\n",
      "            The feature extractor that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained feature extractor inheriting from [`PreTrainedFeatureExtractor`].\n",
      "    \n",
      "            Feature extractors are used for non-NLP models, such as Speech or Vision models as well as multi-modal\n",
      "            models. Multi-modal models will also require a tokenizer to be passed.\n",
      "    \n",
      "            If not provided, the default feature extractor for the given `model` will be loaded (if it is a string). If\n",
      "            `model` is not specified or not a string, then the default feature extractor for `config` is loaded (if it\n",
      "            is a string). However, if `config` is also not given or not a string, then the default feature extractor\n",
      "            for the given `task` will be loaded.\n",
      "        framework (`str`, *optional*):\n",
      "            The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      "            installed.\n",
      "    \n",
      "            If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      "            both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      "            provided.\n",
      "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "            When passing a task name or a string model identifier: The specific model version to use. It can be a\n",
      "            branch name, a tag name, or a commit id, since we use a git-based system for storing models and other\n",
      "            artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n",
      "        use_fast (`bool`, *optional*, defaults to `True`):\n",
      "            Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n",
      "        use_auth_token (`str` or *bool*, *optional*):\n",
      "            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      "            when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      "        device (`int` or `str` or `torch.device`):\n",
      "            Defines the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank like `1`) on which this\n",
      "            pipeline will be allocated.\n",
      "        device_map (`str` or `Dict[str, Union[int, str, torch.device]`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut). When `accelerate` library is present, set\n",
      "            `device_map=\"auto\"` to compute the most optimized `device_map` automatically. [More\n",
      "            information](https://huggingface.co/docs/accelerate/main/en/big_modeling#accelerate.cpu_offload)\n",
      "    \n",
      "            <Tip warning={true}>\n",
      "    \n",
      "            Do not use `device_map` AND `device` at the same time as they will conflict\n",
      "    \n",
      "            </Tip>\n",
      "    \n",
      "        torch_dtype (`str` or `torch.dtype`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
      "            (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`).\n",
      "        trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to allow for custom code defined on the Hub in their own modeling, configuration,\n",
      "            tokenization or even pipeline files. This option should only be set to `True` for repositories you trust\n",
      "            and in which you have read the code, as it will execute code present on the Hub on your local machine.\n",
      "        model_kwargs:\n",
      "            Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,\n",
      "            **model_kwargs)` function.\n",
      "        kwargs:\n",
      "            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n",
      "            corresponding pipeline class for possible values).\n",
      "    \n",
      "    Returns:\n",
      "        [`Pipeline`]: A suitable pipeline for the task.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
      "    \n",
      "    >>> # Sentiment analysis pipeline\n",
      "    >>> pipeline(\"sentiment-analysis\")\n",
      "    \n",
      "    >>> # Question answering pipeline, specifying the checkpoint identifier\n",
      "    >>> pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"bert-base-cased\")\n",
      "    \n",
      "    >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
      "    >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
      "    >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
      "    >>> pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec632275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289e73aa80e843d88eb972244306a65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243fdf50a7f64e31b1fae2b2f8890264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05766ae834cb4c109534f7e760dbffc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7008a9e0394d3296768ac53792754f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline('text-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7c62b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'text-classification',\n",
       " 'model': DistilBertForSequenceClassification(\n",
       "   (distilbert): DistilBertModel(\n",
       "     (embeddings): Embeddings(\n",
       "       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (transformer): Transformer(\n",
       "       (layer): ModuleList(\n",
       "         (0): TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "         (1): TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "         (2): TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "         (3): TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "         (4): TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "         (5): TransformerBlock(\n",
       "           (attention): MultiHeadSelfAttention(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (ffn): FFN(\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (activation): GELUActivation()\n",
       "           )\n",
       "           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       " ),\n",
       " 'tokenizer': PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       " 'feature_extractor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100baffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9776768088340759}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('This is Sai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80087ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
